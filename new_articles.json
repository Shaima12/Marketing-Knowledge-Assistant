[
  {
    "url": "https://www.searchenginejournal.com/case-study-how-entity-linking-can-support-local-search-success/563074/",
    "title": "Case Study: How Entity Linking Can Support Local Search Success via @sejournal, @marthavanberkel",
    "date": "2026-01-20T13:00:32+00:00",
    "content": "Search has changed dramatically, including local search. Search engines and AI systems now incorporate semantic understanding to generate citations and results. To gain semantic understanding, they need to know which topics appear in the content and how they relate to one another so that they can identify your areas of authority.\nFor brands with multiple locations, this shift can create challenges. Search engines often misinterpret place names or the services a location offers, which can lead to the wrong landing page appearing for a near-me query. At the same time, it gives local SEOs a new opportunity to add needed semantic clarity.\nTo support clarity and semantic understanding, SEOs should adopt an entity SEO approach. The topics, also known as entities, are like keywords with multiple dimensions. When defined within your content and with schema markup, entities can bring clarity to AI and search engines.\nIn Microsoft’s recent article titled “Optimizing Your Content for Inclusion in AI Search Answers,” Krishna Madhavan , Bing’s Principal Product Manager, stated:\n“Schema can label your content as a product, review, FAQ, or event, turning plain text into structured data that machines can interpret with confidence.”\nThis semantic understanding is what adds clarity to AI.\nWith more than 47 locations, one of our clients, Brightview Senior Living, needed a way to scale SEO across dozens of markets. Entity linking helped them do exactly that. Their strategy shows what SEOs can start doing today to gain clarity, authority, and better local performance.\nIn the world of Entity SEO, search engines now look beyond keywords for:\nEntities include locations, services, products, people, or anything else with a definable meaning. But identifying an entity is only the first step. Search engines also need to understand the entity’s context, which is where properties in schema markup come in and help disambiguate what the entity actually represents.\nWhen you optimize a page, you describe its main entity. By using the schema.org vocabulary, you can leverage its properties to provide search engines and AI with a structured way to understand the entity.\nFor example, if you’re describing a location, you’d define the physical location as a LocalBusiness entity, using schema properties to describe the business and its service area, and then define the properties that map to the content on the page to describe it.\nNow that you’ve defined the entity using properties, it’s time to add entity linking.\nThere are two types of entity linking: external entity linking and internal entity linking.\nInternal Entity linking is the process of linking to internal entities on your website. External Entity linking is the process of linking entities on your site to their definitions in authoritative knowledge bases such as Wikipedia, Wikidata, or industry-specific glossaries. This is done using schema.org properties such as “sameAs”, “mentions”, “areaServed”, and more. Note that entity linking can use any properties within schema.org.\nBy linking the entities mentioned in your website content to authoritative external sources, you provide search engines with clear, explicit definitions. This reduces ambiguity, improves the relevance of your rankings, and can help your content’s performance in AI summaries and intent-based search experiences.\nFor organizations looking to optimize for local search, place-based entity linking is particularly impactful.\nBrightview Senior Living’s marketing team was responsible for performance across more than 47 community pages, each with its own name, local context, and service mix. Search engines often struggled to interpret these pages correctly, especially when the location name overlapped with a more prominent city elsewhere.\nA prime example was Phoenix, Maryland, being confused with Phoenix, Arizona. This kind of misunderstanding can derail visibility for queries such as “assisted living near me” or “assisted living in Phoenix.”\nTo improve search engines’ understanding of what Brightview offered and where, they needed a future-proof strategy grounded in semantic clarity.\nBrightview shifted from keyword-first SEO to entity-first SEO. Their strategy focused on identifying the entities that defined each location and service offering, then linking them to authoritative definitions to eliminate ambiguity.\nOn each community page, Brightview explicitly defined the location entity and linked it to its authoritative source. For example:\nThis resolved issues such as the Phoenix, Maryland, confusion by telling search engines exactly which Phoenix the content referred to. It also provided a clear geographic signal for near me and geo-modified queries.\nBrightview applied entity linking to core service terms, including assisted living and independent living. These concepts were linked to authoritative sources using “sameAs” and “mentions”.\nThis helped Brightview show up more consistently for non-branded, high-intent searches like “assisted living communities” or “independent living options,” which are critical touchpoints early in the customer journey.\nBy linking assisted living to a known entity, search engines recognized Brightview’s content as authoritative on the topic. This moved Brightview beyond brand-dependent queries and into the realm of broader, category-level search visibility.\nEntity linking was applied across community pages, blog posts, and informational resources. This built a connected content knowledge graph that reinforced Brightview’s authority across both topics and locations that mattered most to their organization.\nThe result was a site where search engines could clearly understand what each page was about, what locations it represented, and how those pages related to Brightview’s broader expertise.\nBy disambiguating locations and services, Brightview made it easier for AI systems to return correct answers when users searched for care options in specific regions.\nAfter implementing entity linking, Brightview saw measurable gains in both local and non-branded visibility.\nNon-branded queries often indicate users who have not yet chosen a provider and who are actively evaluating options.\nBy clearly defining their service entities using schema markup, Brightview achieved:\nThis shift shows how entity linking helps organizations rank for what they do and where they do it , not just who they are.\nWith place-based external entity linking in place, Brightview’s community pages performed better for high-intent local searches. Search engines better understood the connection between each community and its service area.\nPages that used clear, linked location data were more reliably served for near-me and city-based queries.\nAs AI Overviews reshape the SERP with zero-click search, many brands have seen their click-through rate drop. Brightview’s CTR remained strong relative to benchmarks. Clear entity definitions helped search engines and AI models surface their content accurately, even as the search landscape shifted.\nRyan Pitcheralle, Brightview’s SEO consultant, noted that the strength of their schema markup implementation was a direct driver of performance. As he put it, their results showed “complete causation, not just correlation. This is why we’ve stayed competitive in clickthrough rate and performance while everyone else is sliding.”\nEntity linking is not only a technical tactic. It is a strategic opportunity to clarify what your organization should be known for. Here is how to apply it effectively.\nYour website contains many entities, but you do not need to link them all. Focus on the ones that support clarity and strategic differentiation.\nConsistently linking these entities signals to search engines where your expertise lies.\nEntity linking is a key part of creating a content knowledge graph that shows search engines the relationships between your locations, offerings, resources, and brand. Your content knowledge graph helps machines infer meaning, understand context, and deliver more accurate results about your organization that can make or break conversions.\nLocal search hinges on clarity. Search engines need explicit signals about:\nPlace-based entity linking provides that clarity and increases your chances of ranking for geo-modified and near-me queries.\nAI search experiences rely on correctly interpreted entities. When locations, services, and concepts are linked to authoritative sources, AI systems can return more accurate, helpful answers and are more likely to reference your content correctly.\nBrightview’s success shows that entity linking is a practical, high-impact way to strengthen local search performance. By clarifying locations, services, and key concepts, you can help search engines and AI systems understand exactly what your content represents.\nEntity linking improves semantic accuracy and builds the foundation for long-term authority. For SEO and marketing leaders, it is one of the most actionable ways to prepare for the future of semantic and AI-driven search."
  },
  {
    "url": "https://www.searchenginejournal.com/perplexity-ai-interview-explains-how-ai-search-works/565395/",
    "title": "Perplexity AI Interview Explains How AI Search Works via @sejournal, @martinibuster",
    "date": "2026-01-20T12:52:44+00:00",
    "content": "I recently spoke with Jesse Dwyer of Perplexity about SEO and AI search about what SEOs should be focusing on in terms of optimizing for AI search. His answers offered useful feedback about what publishers and SEOs should be focusing on right now.\nAn important takeaway that Jesse shared is that personalization is completely changing\n“I’d have to say the biggest/simplest thing to remember about AEO vs SEO is it’s no longer a zero sum game. Two people with the same query can get a different answer on commercial search, if the AI tool they’re using loads personal memory into the context window (Perplexity, ChatGPT).\nA lot of this comes down to the technology of the index (why there actually is a difference between GEO and AEO). But yes, it is currently accurate to say (most) traditional SEO best practices still apply.”\nThe takeaway from Dwyer’s response is that search visibility is no longer about a single consistent search result. Personal context as a role in AI answers means that two users can receive significantly different answers to the same query with possibly different underlying content sources.\nWhile the underlying infrastructure is still a classic search index, SEO still plays a role in determining whether content is eligible to be retrieved at all. Perplexity AI is said to use a form of PageRank, which is a link-based method of determining the popularity and relevance of websites, so that provides a hint about some of what SEOs should be focusing on.\nHowever, as you’ll see, what is retrieved is vastly different than in classic search.\nSo what you’re saying (and correct me if I’m wrong or slightly off) is that Classic Search tends to reliably show the same ten sites for a given query. But for AI search, because of the contextual nature of AI conversations, they’re more likely to provide a different answer for each user.\nJesse continued his answer by talking about what goes on behind the scenes to generate an answer in AI search.\n“As for the index technology, the biggest difference in AI search right now comes down to whole-document vs. “sub-document” processing.\nTraditional search engines index at the whole document level. They look at a webpage, score it, and file it.\nWhen you use an AI tool built on this architecture (like ChatGPT web search), it essentially performs a classic search, grabs the top 10–50 documents, then asks the LLM to generate a summary. That’s why GPT search gets described as “4 Bing searches in a trenchcoat” —the joke is directionally accurate, because the model is generating an output based on standard search results.\nThis is why we call the optimization strategy for this GEO (Generative Engine Optimization). That whole-document search is essentially still algorithmic search, not AI, since the data in the index is all the normal page scoring we’re used to in SEO. The AI-first approach is known as “sub-document processing.”\nInstead of indexing whole pages, the engine indexes specific, granular snippets (not to be confused with what SEO’s know as “featured snippets”). A snippet, in AI parlance, is about 5-7 tokens, or 2-4 words, except the text has been converted into numbers, (by the fundamental AI process known as a “transformer”, which is the T in GPT). When you query a sub-document system, it doesn’t retrieve 50 documents; it retrieves about 130,000 tokens of the most relevant snippets (about 26K snippets) to feed the AI.\nThose numbers aren’t precise, though. The actual number of snippets always equals a total number of tokens that matches the full capacity of the specific LLM’s context window. (Currently they average about 130K tokens). The goal is to completely fill the AI model’s context window with the most relevant information, because when you saturate that window, you leave the model no room to ‘hallucinate’ or make things up.\nIn other words, it stops being a creative generator and delivers a more accurate answer. This sub-document method is where the industry is moving, and why it is more accurate to be called AEO (Answer Engine Optimization).\nObviously this description is a bit of an oversimplification. But the personal context that makes each search no longer a universal result for every user is because the LLM can take everything it knows about the searcher and use that to help fill out the full context window. Which is a lot more info than a Google user profile.\nThe competitive differentiation of a company like Perplexity, or any other AI search company that moves to sub-document processing, takes place in the technology between the index and the 26K snippets. With techniques like modulating compute, query reformulation, and proprietary models that run across the index itself, we can get those snippets to be more relevant to the query, which is the biggest lever for getting a better, richer answer.\nBtw, this is less relevant to SEO’s, but this whole concept is also why Perplexity’s search API is so legit. For devs building search into any product, the difference is night and day.”\nDwyer contrasts two fundamentally different indexing and retrieval approaches:\nIn the first version, AI sits on top of traditional search and summarizes ranked pages. In the second, the AI system retrieves fragments directly and never reasons over full documents at all.\nHe also described that answer quality is constrained by context-window saturation, that accuracy emerges from filling the model’s entire context window with relevant fragments. When retrieval succeeds at saturating that window, the model has little capacity to invent facts or hallucinate.\nLastly, he says that “modulating compute, query reformulation, and proprietary models” is part of their secret sauce for retrieving snippets that are highly relevant to the search query.\nFeatured Image by Shutterstock/Summit Art Creations"
  },
  {
    "url": "https://martech.org/iab-launches-event-and-conversion-api-to-standardize-advertisers-shared-data/",
    "title": "IAB launches Event and Conversion API to standardize advertisers’ shared data",
    "date": "2026-01-20T13:46:00+00:00",
    "content": "The IAB Tech Lab has introduced the Event and Conversion API (ECAPI) to standardize how advertisers communicate key marketing events and conversions to platforms and partners. It’s open for public comment through February 20, 2026.\nThe goal? Less friction, more clarity. “Advertisers and platforms are already doing this in parallel,” said Anthony Katsur, CEO of IAB Tech Lab, in a statement. “ECAPI gives everyone a shared foundation so teams can focus on results, not endless integrations.”\nDig deeper: 5 ways to improve marketing measurement in 2026\nAt its core, ECAPI defines a common set of full-funnel events — from upper-funnel engagement to bottom-funnel conversions — that advertisers can send in a consistent format. That means cleaner data for platforms, better inputs for AI agents, and smoother, more consistent campaign optimization across the board.\nToday, many platforms run their own versions of Conversion APIs. But that often means custom work for every integration — time-consuming and complex to scale, especially as outcome-based buying gains traction. ECAPI offers a standardized, flexible alternative that still allows for platform-specific needs without reinventing the wheel.\nThis spec is also part of IAB Tech Lab’s broader push toward agentic marketing, where AI agents optimize outcomes across the funnel based on shared signals and measurable goals.\n“Instead of rebuilding the same solutions over and over, we can focus on the value of the data,” Barbara Kalicki, Associate Director at Publicis Sapient, said in a statement.\nTo participate in the public comment process, which will remain open until February 20, 2026, go to https://iabtechlab.com/standards/ecapi/ ."
  },
  {
    "url": "https://martech.org/why-engagement-metrics-matter-more-than-sessions-in-ai-search/",
    "title": "Why engagement metrics matter more than sessions in AI search",
    "date": "2026-01-20T13:39:00+00:00",
    "content": "For more than a decade, sessions have been among the most relied-on metrics in digital marketing. They offered a simple and intuitive way to measure growth. More sessions meant more visibility. More visibility meant better SEO performance. For leadership teams, session growth became shorthand for success in organic search. That mental model is no longer reliable.\nAI-led search experiences are reshaping how users discover, consume and trust information. Search platforms increasingly summarize answers, infer intent and present conclusions directly, often without redirecting users to a website.\nIn this environment, traffic volume becomes an incomplete and sometimes misleading signal. What matters more is how users behave when they do engage with content, because behavior is what AI systems learn from.\nThis is where engagement metrics shift from a supporting detail to the primary lens for evaluating search performance.\nA session is a record of arrival. It indicates that a user reached your site and initiated an interaction. It does not indicate whether the content helped, confused or failed them altogether. In a click-based search world, that limitation was acceptable because ranking position and click-through rate acted as rough proxies for relevance.\nAI systems do not operate on proxies. They operate on outcomes. When AI models assess content quality, they are not evaluating how often a page is visited. They are determining whether the content resolves the task that prompted the search. Sessions do not measure resolution. They measure access.\nAs AI search reduces the number of clicks required to satisfy informational intent, session counts will naturally decline for many sites, even when those sites remain influential. Treating that decline as a performance failure creates strategic risk, particularly for organizations that continue to optimize for volume rather than value.\nDig deeper: 6 things marketers need to know about search and discovery in 2026\nGoogle Analytics 4 (GA4) represents a deliberate shift away from session-centric thinking, even though many organizations still use it for session reporting. GA4 is built around events and engaged sessions, not simple visits. This architectural change reflects a broader shift in how interaction quality is measured.\nIn GA4, engagement time replaces bounce rate as a primary behavioral signal. An engaged session is defined not by duration alone, but by whether meaningful interaction occurs. This includes scrolling, clicking, video playback or sustained attention.\nFrom an AI search perspective, these signals matter because they indicate whether content is being consumed with intent. A page that attracts fewer users but consistently generates more extended engagement and more interactions sends a stronger quality signal than a page that attracts large volumes of traffic with minimal engagement.\nThe implication is clear. GA4 should not be treated as a traffic dashboard. It should be treated as a behavior analysis platform that shows how content performs after discovery.\nAI systems are trained to infer understanding from patterns. While marketers often think in terms of keywords and rankings, AI models think in terms of satisfaction and consistency. Engagement metrics provide indirect but consequential evidence of whether users found what they needed.\nMetrics such as average engagement time, scroll depth and event frequency reveal whether users are reading content or skimming past it. They indicate whether users pause at key sections, interact with explanatory elements or quickly abandon the page.\nThese behaviors matter because they reflect the judgments that AI systems aim to model. If thousands of users consistently engage deeply with a page, that page begins to look like a reliable source. If thousands of users consistently disengage, the opposite conclusion is drawn. Sessions alone cannot capture this distinction.\nDig deeper: Why it’s time to treat AI referrals as their own channel in GA4\nWhile GA4 excels at quantifying engagement patterns, Microsoft Clarity adds a qualitative layer that is especially valuable for SEO and AI-led search analysis. Clarity makes behavior visible in ways that aggregated metrics cannot.\nSession recordings, heatmaps and interaction timelines allow teams to see exactly how users experience content. They reveal hesitation, confusion, frustration and shifts in intent in real time. These signals are not just UX insights. They are early indicators of content misalignment.\nFor example, rage clicks often indicate unmet expectations. Dead clicks suggest unclear affordances. Excessive scrolling followed by abandonment can signal that users are searching for an answer that never appears. These behaviors indicate whether content resolves intent or creates friction.\nFrom an AI perspective, friction matters. Content that consistently frustrates users is unlikely to be treated as authoritative or reliable over time, regardless of how well it is optimized for keywords.\nAI search systems aim to reduce user uncertainty. They prioritize sources that consistently deliver clarity. Engagement metrics act as a proxy for that clarity. When users stay, read, interact with and return, they signal that the content helped them make sense of it. When users leave quickly or behave erratically, they signal that the content failed to meet expectations.\nOver time, AI models learn from these patterns. They know which sources effectively satisfy intent and which do not. This learning process favors depth, structure and relevance over surface-level optimization. Engagement metrics capture this learning signal far better than session counts ever could.\nDig deeper: How GA4 records traffic from Perplexity Comet and ChatGPT Atlas\nOne of the biggest challenges for marketing leaders is explaining why SEO performance can appear to decline in dashboards while brand presence and influence remain strong. This disconnect often stems from an overreliance on sessions as a primary KPI.\nWhen AI answers reduce the need for clicks, session-based reporting underrepresents real impact. Engagement-based reporting, on the other hand, focuses attention on the interactions that still matter.\nGA4 engagement reports, combined with Clarity behavioral analysis, enable leaders to answer more meaningful questions.\nThese are the questions AI systems implicitly ask as well.\nOptimizing for engagement changes how content is created. Instead of aiming to attract as many visitors as possible, teams begin to focus on helping fewer visitors more effectively.\nThis often leads to more transparent structure, more explicit answers and better alignment between intent and content. Pages shift from ranking for a topic to resolving a problem.\nFrom an SEO perspective, this approach is more sustainable in an AI-led search environment. Content that genuinely helps users is more likely to be reused, summarized or cited by AI systems, even when click volume declines.\nThe shift from sessions to engagement requires a change in mindset as much as a change in tooling. Leaders should expect traffic volatility as AI search evolves and resist the temptation to equate declining sessions with declining relevance.\nInstead, they should invest in understanding engagement quality through GA4 and Clarity together. GA4 provides scale and pattern recognition. Clarity provides context and explanation. When used together, these tools support better decisions about content investment, technical prioritization and SEO strategy. They help organizations align measurement with how discovery actually works today.\nIn an AI-led search landscape, visibility is no longer defined solely by clicks. Influence persists even when traffic is absent. Engagement metrics provide the closest available signal to how that influence is earned and maintained. Sessions will always have a place in reporting, but they should no longer be the headline metric for organic search success. Engagement tells a deeper story about usefulness, trust and understanding.\nFor organizations serious about long-term visibility in AI-driven discovery, that story matters far more than raw volume ever did.\nDig deeper: How to set up GA4 cross-domain tracking for global and multi-brand sites"
  }
]