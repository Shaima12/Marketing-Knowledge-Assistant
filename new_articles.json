[
  {
    "url": "https://blog.hubspot.com/marketing/what-we-learned-building-salesbot",
    "title": "What we learned building SalesBot — HubSpot’s AI-powered chatbot selling assistant",
    "date": "2025-12-29T12:00:03+00:00",
    "content": "When I first joined HubSpot’s Conversational Marketing team, most of our website chat volume was handled by humans. We had a global team of more than a hundred live sales agents — Inbound Success Coaches (ISCs) qualifying leads, booking meetings, and routing conversations to sales reps. It worked, but it didn’t scale.\nEvery day, those ISCs fielded thousands of chat messages from visitors who needed product info, had support questions, or were just exploring. While we loved those interactions, they often pulled focus from high-intent prospects ready to engage with sales.\nWe knew AI could help us work smarter, but we didn’t want another scripted chatbot. We wanted something that could think like a sales rep: qualify, guide, and sell in real-time.\nThat’s how SalesBot was born — an AI-powered chat assistant that now handles the majority of HubSpot’s inbound chat volume, answering thousands of chatter questions, qualifying leads, booking meetings, and even directly selling our Starter-tier products.\nWhen we first launched SalesBot, our primary goal was to deflect easy-to-answer, low sales intent questions (example: “What’s a CRM” or “How do I add a user to my account” ). We wanted to reduce the noise and free up humans to focus on more complex conversations.\nWe trained the bot on HubSpot’s knowledge base, product catalog, Academy courses, and more. We are now deflecting over 80% of chats across our website using AI and self-service options.\nThat success in deflection gave us confidence, but it also revealed our next challenge. Deflection alone doesn’t grow the business. To truly scale value, we needed a tool that does more than resolve — it has to sell .\nOnce we introduced deflection, we noticed a drop-off in medium-intent leads — the ones that weren’t ready to book a meeting but still showed buying signals. Humans are great at spotting those moments. Bots aren’t … yet.\nTo close that gap, we built a real-time propensity model that scores chats on a scale of 0–100 based on a blend of CRM data, conversation content, and AI-predicted intent. When a chat crosses a certain threshold, it’s raised as a qualified lead.\nThat model now helps SalesBot identify high-potential opportunities — even when a customer doesn’t explicitly ask for a demo. It’s a perfect example of how AI can surface nuance at scale.\nOnce we’d nailed the foundations of deflection and scoring, we turned our attention to something bolder: turning SalesBot into a true selling assistant.\nWe trained it on our qualification framework (GPCT — Goals, Plans, Challenges, Timeline), enabling the bot to guide prospects toward the right next step: whether that’s getting started with free tools, booking a meeting with sales, or purchasing a Starter plan directly in chat.\nNow, we have a tool that doesn’t just respond — it qualifies, builds intent, and pitches like a rep. That shift fundamentally changed how we think about conversational demand generation.\nWe quickly realized that traditional chatbot metrics like CSAT (Customer Satisfaction Score) weren’t enough.\nCSAT measures how a customer feels about their experience, typically by asking whether they were a detractor, passive, or promoter after an interaction. But only a small portion (less than 1% of chatters) complete the survey. And even if a customer rates a chat positively, that doesn’t necessarily mean the Salesbot was providing a quality chat experience.\nSo we built a custom quality rubric with our top-performing ISCs to define what “good” actually looks like. The rubric measures factors like discovery depth, next steps, tone, and accuracy.\nThis year alone, a team of 13 evaluators manually reviewed more than 3,000 sales conversations. That human QA loop is critical. It keeps our AI grounded in real-world selling behavior and helps us continuously improve performance.\nBefore AI, staffing live chat in seven languages was one of our biggest operational challenges. It was costly, inconsistent, and hard to scale.\nNow, we can handle multilingual conversations around the world, providing a consistent experience no matter where someone’s chatting from. That’s not just an efficiency win — it’s a customer experience upgrade.\nAI has given us true global coverage without overextending our team, unlocking growth in regions where headcount simply couldn’t keep up.\nSuccess didn’t happen because of one person or team — it happened because a group of smart, customer-driven builders came together across Conversational Marketing and Marketing Technology AI Engineering.\nConversational Marketing owned the strategy, user experience, and quality assurance, always grounding decisions in what would deliver the best experience for our customers. Our AI Engineering partners in Marketing Technology built the models, prompts, and infrastructure that made those ideas real — fast.\nTogether, we formed a unified working group with shared goals, a common backlog, and a rhythm of weekly experimentation. That mix of deep customer empathy and technical excellence let us move like a product team — testing, learning, and improving SalesBot with every release.\nThe biggest unlock in our journey was embracing a product mindset. SalesBot wasn’t a one-off automation project. It’s a living product that evolves with every iteration.\nOver the past two years, we’ve moved from rule-based bots to a retrieval-augmented generation (RAG) system, upgraded our models to GPT-4.1, and added smarter qualification and product-pitching capabilities.\nThose upgrades doubled response speed, improved accuracy, and lifted our qualified lead conversion rate from 3% to 5%.\nWe didn’t get there overnight. It took hundreds of iterations and a culture that treats AI experimentation as a core part of the go-to-market motion.\nEven with all this progress, some things still require a human touch. Today, SalesBot can’t build custom quotes, handle complex objections, or replicate empathy in nuanced conversations — and that’s okay. We’ll always be working toward expanding its capabilities, but human oversight will always be essential to maintaining quality.\nOur agents and subject matter experts play a core role in our success. They evaluate outputs, provide feedback, and ensure the system continues to learn and improve. Their judgment defines what “good” looks like and keeps our standard of quality high as the technology evolves.\nAI’s role is to scale reach and speed — not to replace human connection. Our ISCs now focus on higher-value programs and edge cases where their expertise truly shines. The goal isn’t fewer humans — it’s smarter, more impactful use of their time.\nWhen we first built SalesBot, it ran on a simple rules-based system — X action triggers Y response. It worked for basic logic, but it didn’t sound like a salesperson. We wanted something that felt closer to an ISC: conversational, confident, and helpful.\nTo get there, we experimented with fine-tuning. We exported thousands of chat transcripts and had ISCs annotate them for tone, accuracy, and phrasing. Training the model on these examples made it sound more natural, but accuracy dropped. We learned the hard way that too much unstructured human data can actually degrade model performance. The model starts remembering the “edges” of what it sees and blurring everything in between.\nSo, we pivoted. Instead of giving the model more data, we gave it a better structure. We moved to a retrieval-augmented generation (RAG) setup, grounding the tool in real-time context and teaching it when to pull from knowledge sources, tools, and CRM data.\nThe result is a bot that’s significantly more reliable in complex sales conversations and far better at identifying intent.\nIf you're just getting started, the biggest misconception is that you can jump straight into AI. In reality, AI only succeeds when the foundation beneath it is strong. Looking back at our journey, these three principles mattered the most.\nAI is only as good as the human program it learns from. Before we automated anything, we had years of real conversations handled by skilled chat agents. That live chat foundation gave us:\nIf you skip this step, your AI won’t know what “good” is — and it won’t know when it’s wrong.\nAI can’t replicate the nuances that come with human interaction.\nStudy your top-performing reps deeply, and ask yourself the following questions:\nYour human team is your blueprint. Everything great humans do — from tone to timing to discovery — becomes the foundation for an AI that can actually sell, not just answer questions.\nAI is not a set-it-and-forget-it project. Tt’s a product, and the only way to scale an AI chat program is to build a team that:\nAn experiment-driven team turns AI from a one-time launch into a continuously improving engine for growth.\nThe biggest takeaway for me is this: AI doesn’t replace great go-to-market strategy — it accelerates it. Your tools should be a reflection of how you operate. For us, that’s a blend of technology, creativity, and customer empathy to keep evolving how we sell."
  },
  {
    "url": "https://www.searchenginejournal.com/year-review-highlights-and-lowlights-for-seo/562698/",
    "title": "Review Of 2025: Highlights & Lowlights For SEO (& WordPress) via @sejournal, @martinibuster",
    "date": "2025-12-29T12:00:34+00:00",
    "content": "It was a landmark year in SEO, largely driven by the uncertainty introduced by AI Search. The year began with the digital marketing community questioning its relevance and ended with a strong affirmation of its central position as it gradually adjusted to new realities. WordPress entered the year with uncertainty about whether the core would see meaningful updates and closed out the year with version 6.9, an update that strongly positions it for AI-led innovations.\n2025 is the year that GEO went mainstream, energized by client demand for solutions that are specific to AI Search. This resulted in the somewhat awkward situation of some SEOs pivoting to providing GEO-specific services while simultaneously affirming SEO best practices for ranking in AI search. Attempts to define GEO as a process distinct from SEO generally fell short .\nWordPress SEO plugins faced a similar issue with clients demanding GEO-specific solutions, leading to the introduction of LLMs.txt generation features. LLMs.txt is a proposed standard for providing content to AI; however, it’s a solution in search of existential justification because no AI companies use or have plans to adopt the standard.\nWhile other WordPress SEO plugins justified LLMs.txt support as a future-proofing feature, the Squirrly SEO WordPress plugin was refreshingly candid about its reasons for introducing it:\n“I know that many of you love using Squirrly SEO and want to keep using it. Which is why you’ve asked us to bring this feature.\nBut, because I care about you: know that LLMs txt will not help you magically appear in AI search. There is currently zero proof that it helps with being promoted by AI search engines.”\nGoogle’s John Mueller has strongly and unambiguously insisted there are many reasons why the LLMs.txt proposal is not viable . Thus, many were startled and amused when Lidia Infante discovered that Google itself was using LLMs.txt. The LLMs.txt file was quickly removed, but that didn’t stop some GEO “experts” from crowing that Google’s use of the file validates LLMs.txt, apparently unaware that Google had already removed it.\nIn remarks at the New York City Search Central Live event (which I attended), Google’s Danny Sullivan encouraged SEOs and businesses to think about how they can differentiate themselves as brands in order to improve their search visibility.\n“And I’ve seen where people do research and say, ‘I’ve figured out that if you have a lot of branded searches…’ That’s kind of valid in some sense.\n…What it’s saying is that people have recognized you as a brand, which is a good thing. We like brands. Some brands we don’t like, but at least we recognize them, right?\nSo if you’re trying to be found in the sea of content and you have the 150,000th fried chicken recipe, it’s very difficult to understand which ones of those are necessarily better than anybody else’s out there.\nBut if you are recognized as a brand in your field, big, small, whatever, just a brand, then that’s important.\nThat correlates with a lot of signals of perhaps success with search. Not that you’re a brand but that people are recognizing you. People may be coming to you directly, people, may be referring to you in lots of different ways… You’re not just sort of this anonymous type of thing.”\nSullivan’s reference to “branded searches” may have been a reference to an article I wrote about Google’s branded search patent that describes the use of branded search queries as ranking factors.\nPeople think of “brand” in terms of something that big sites have and little sites do not. But the reality is that brand is just what people think about a company, and the challenge for any business is to distinguish itself from its competitors in such a way that its customers and site visitors remember it, ask for it by name on Google search, and recommend the site to their friends. That, in a nutshell, is how I interpret what Danny Sullivan was communicating.\nUser behavior is a trusted source of signals that can indicate qualities like expertise, experience, authoritativeness, and trustworthiness (E-E-A-T). E-E-A-T is not something that an SEO adds to a website . While Google has cryptically referred to signals that it uses to determine qualities related to E-E-A-T, in my opinion, those signals are likely related to how users react to a website, user behavior signals .\nRead what Danny Sullivan said: Google’s SEO Tips For Better Rankings – Search Central Live NYC\nThis year saw the publication of a number of research papers and patents that point to improvements in AI and algorithms that may play a role in how webpages are ranked.\nGoogle filed a patent that describes how an LLM can organize related search results by themes and then provide a short summary. It describes a deep research method that closely parallels what we see happening in AI Mode.\n“In some examples, in response to the search query being generated, the thematic search engine may generate thematic data from at least a portion of the search results. For example, the thematic search engine may obtain the search results and may generate narrower themes (e.g., sub-themes) (e.g., “neighborhood A”, “neighborhood B”, “neighborhood C”) from the responsive documents of the search results. The search results page may display the sub-themes of theme and/or the thematic search results for the search query. The process may continue, where selection of a sub-theme of theme may cause the thematic search engine to obtain another set of search results from the search engine and may generate narrower themes (e.g., sub-sub-themes of theme) from the search results and so forth.”\nThe takeaway from the above passage is that an AI system that incorporates what’s in the patent is still relying on a search engine for retrieving the documents. What those who are interested in GEO need to wrap their heads around is that what’s being ranked for a given search query is vastly different from classic search because it’s generating “sub-themes” of the initial query and then ranking those webpages in addition to the initial query.\nInsight About GEO: While the underlying infrastructure is still classic search, what’s getting ranked is not classic search relative to the initial query. This is the nuance that genuinely distinguishes GEO from SEO.\nThe patent also describes a summary generator that groups answers by themes using data from passages from documents, but may also use data from titles, metadata, and surrounding passages.\nGoogle filed a patent about using five real-world contextual signals to influence the answers that an AI answer engine provides.\nThe five factors that this system describes as influencing LLM answers are:\nThe first four factors influence the answers provided by the LLM. The last one influences whether to turn off LLM-assisted answers and revert to standard AI answers.\nAn interesting part of this patent is about the concept of “related intents.”\n“For example, …one or more of the LLMs can determine an intent associated with the given assistant query… Further, the one or more of the LLMs can identify, based on the intent associated with the given assistant query, at least one related intent that is related to the intent associated with the given assistant query… Moreover, the one or more of the LLMs can generate the additional assistant query based on the at least one related intent.”\nThis patent is useful for understanding how AI Search differs from Classic Search. It describes a way that AI systems can personalize answers with context-aware responses.\nRead more: Google Patent On Using Contextual Signals Beyond Query Semantics\nThis patent is about solving a user’s problem of identifying where they read about a certain topic, whether the topic was in an email or a webpage. The name of the patent is Generating Query Answers From A User’s History .\nTraditional email search did not enable natural language querying; it still relied on basic keyword-matching algorithms. This patent solves that problem, partially through the ability to understand fuzzy queries.\n“For example, the browser history collection… may include a list of web pages that were accessed by the user. The search engine… may obtain documents from the index… based on the filters from the formatted query.\nFor example, if the formatted query… includes a date filter (e.g., “last week”) and a topic filter (e.g., “chess story”), the search engine… may retrieve only documents from the collection… that satisfy these filters, i.e., documents that the user accessed in the previous week that relate to a “chess story.””\nRead more: Google Files New Patent On Personal History-Based Search\nGoogle published a research paper introducing a new method for determining whether retrieved content provides enough information to answer a query. The breakthrough makes it possible to identify when retrieved context is incomplete or insufficient, which is a major source of hallucinations in RAG systems.\nSEO Takeaway: The research paper underscores the importance of ensuring that published content contains the necessary context to fully support the topics it covers.\nRead more: Google Researchers Improve RAG With “Sufficient Context” Signal\nGoogle’s MUVERA enables multi-vector models to retrieve at speeds comparable to single-vector systems while preserving their ability to perform token-level matching. Token-level matching means the model compares each individual word in the query to individual words in the content it evaluates. MUVERA keeps the accuracy advantages of multi-vector models while removing the heavy computation in the retrieval step by learning efficient virtual document vectors that approximate multi-vector scoring.\nWordPress generated buzz in the developer community with the announcement of the WordPress Abilities API , a way to safely integrate external plugin functionalities into WordPress in a more unified, less fragmented way. This also lays the foundation for a dramatic expansion of capabilities with AI.\n“This API creates a centralized registry where all functionalities can be formally registered with well-defined schemas, comprehensive descriptions, and explicit permissions. By adopting this common language, plugins and themes will empower AI-driven solutions to seamlessly discover, interpret, utilize, and coordinate capabilities throughout the entire WordPress ecosystem.”\nThe December State of the Word event in San Francisco provided a sneak peek at the improvements AI will play in online publishing. WordPress co-creator Matt Mullenweg said that he envisions hundreds, if not thousands, of specialized AI models integrated into different levels of the WordPress workflow.\n“So I imagine that in the future, we’ll actually have hundreds, if not thousands, of different specialized models that might be tuned for different things. In fact, in some of our work at Automattic around like a site builder, we’re finding that models that are tuned specifically for like logo creation can be essentially fine-tuned or smaller, cheaper to run, sort of less memory, etcetera, can do more specialized tasks.”\nMullenweg views a future in which narrowly focused models contribute to different parts of the publishing process, showing how WordPress expects AI to take on routine creative tasks so that users can focus on the work that matters, further democratizing the act of publishing online.\nGoogle blocked rank trackers from scraping the top 100 search results. An unexpected consequence of blocking rank trackers from scraping the top 100 search results is that Google Search Console began reporting fewer keyword impressions, sending SEOs and businesses into a panic. It turned out that rank trackers had been inflating the Search Console impression data .\nThis, in turn, caused some SEOs to revise the idea of zero-click searches, an idea dating from at least 2019, that blamed a low click-to-impression ratio on things like Featured Snippets. In hindsight, that low ratio of clicks to impressions was likely due to inflated impression data.\nThe irony of the zero-click idea being revisited is that businesses in 2025 are reporting declines in traffic that are blamed on Google’s AI Overviews and AI Mode. The biggest story of the year related to SEO is arguably the decline of search clicks.\nWhile Google’s CEO Sundar Pichai insisted that Google’s AI Overviews is sending more clicks than ever , SEOs and their clients strongly disagreed with that point of view.\nThe news dominating the WordPress world in 2025 was Automattic and WordPress co-creator Matt Mullenweg’s self-described “nuclear” attacks against WP Engine, which included publishing a website with the goal of encouraging WP Engine’s customers to migrate away, locking WP Engine out of the WordPress ecosystem, and creating a copy of WP Engine’s premium version of their ACF plugin.\nThe basis for the conflict is what Mullenweg describes as WP Engine’s lack of support for the open-source WordPress project. WP Engine responded with a federal lawsuit against Mullenweg and Automattic, seeking to hold them responsible for actions that WP Engine argued hindered its business.\nMany months later, Automattic responded with a counterclaim against WP Engine, using creative statistics about WP Engine’s use of SEO that, in my expert opinion, don’t hold up on closer scrutiny ( Read: Automattic’s Legal Claims About SEO… Is This Real? ).\nAutomattic and Matt Mullenweg are on solid ground to encourage big corporations to give back to the WordPress community because it supports the long-term viability of the WordPress open source project. It’s quite likely that many in the WordPress community would have rallied behind Mullenweg against WP Engine if he had pursued a less extreme approach toward WP Engine.\nWhat happened between Mullenweg and WP Engine arguably backfired on Mullenweg, generating substantial negative sentiment against him that persists to this very day. The effect is that many in the community are siding against Mullenweg while simultaneously not necessarily siding with WP Engine.\nAn example of how the negativity persists, Kevin Geary, the creator of the Etch WordPress page builder, recently tweeted :\n“As usual, the adults do sensible things and serve the community, and all Matt can do is p— on us and wreak havoc.\nWP is an unserious org led by an unserious person. Embarrassing.”\nAnother example: It didn’t take long for negative sentiment against Mullenweg to arise in a recent popular Reddit discussion about Automattic’s SCF plugin, a fork of WP Engine’s premium ACF plugin.\n“ACF vs SCF this far along – have they diverged? Politics and such aside – , what is the difference now between Advanced Custom Fields and Secure Custom Fields after some time developing?”\n“When you say “politics and such aside,” it’s pretty hard to put GPL theft of the most extreme WordPress has ever seen aside.\n“Man u must have missed it when the wordpress owner had a feud with wpengine over their branding and spiraled and then stole the ACF plugin and renamed it and started just burning bridges and flexing ownership ability\nHe even put some petty checkbox on the wp login screen like check this box that you’re in no way working with WPEngine or you can’t log in\nIt was crazy / petty / weird and then in the end scary for all plugin devs that what you thought was open source could be manhandled and banned and stolen or replaced by one guy at the top of wordpress\nMany people are grateful to Matt Mullenweg for what he’s accomplished with WordPress. But, as the Redditor commented, the conflict was “sad to see.” One doesn’t have to click around the web for long to discover evidence of the extremely negative sentiment that follows Mullenweg around across the internet.\n2025 was largely a year of transition. Everything, from SEO to WordPress to the tools that online businesses use, was in the process of preparing for what comes next. In terms of internet marketing, 2025 was the gateway to 2026."
  }
]