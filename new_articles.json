[
  {
    "url": "https://blog.hubspot.com/marketing/building-customer-trust-ai",
    "title": "Building systems of trust in the age of AI while staying human at heart",
    "date": "2025-12-19T12:00:04+00:00",
    "content": "When I joined HubSpot, I stepped into a rare position. I had already spent years as a customer, learning how to build systems creatively with the tools I had access to. Then, I joined the company with the responsibility of modernizing a long-standing customer reference system that had served many teams well but was now struggling to meet new expectations, complexity, and scale.\nSeeing both sides changed how I approached this work. Advocacy is often misunderstood. It can be seen as simple or administrative because so much of its complexity lives behind the scenes. But once you look closely, you realize it requires nuance, discernment, finesse, and emotional intelligence at every step.\nMy goal was not to replace any of that. It was to create a system that supported it.\nIf you have ever tried to build trust at scale, you likely know firsthand how challenging the work can be. So, consider this a look inside what we rebuilt at HubSpot, how we approached it, and how you can apply the same principles without needing an engineer or a separate platform. And speaking as someone who is very much not an engineer — only a marketer armed with a MacBook and grit — if I can build this, you can too.\nIf there has been one theme throughout this journey, it is that AI is not the threat to fear. Inconsistency is. AI did not remove the human parts of this work. It clarified where they matter most.\nEvery organization relies on work that is often invisible but deeply impactful:\nAdvocacy teams live here every day. They build credibility, connection, and proof in ways that are easy to underestimate when the process is scattered or opaque. As both a former customer and now a HubSpotter, I saw just how often the work was undervalued, not intentionally but because its complexity was hidden.\nThe goal of this rebuild was to make that work visible, respected, and supported so that people had the structure they needed to excel.\nAs we redesigned the reference process, one thing became very clear: the system had grown more complicated over time. This wasn’t because the work was flawed. The people who were trying to help were filling gaps manually.\nThe old process required 18 disconnected steps. After the rebuild, it became a connected sequence of five clear phases.\nThe most surprising outcome was how well AI paired with human judgment. It did not eliminate the need for nuance or relationship context. It supported it.\nThis gave people more time to focus on the parts only humans can do: storytelling, empathy, nuance, and partnership.\nAs the new system came together, it became clear that we were not just building workflows — we were also shaping how trust moves through an organization.\nWhen teams gain transparency into advocacy work, three things reliably happen:\nWhen people can see how their involvement matters, participation grows organically. This was one of the strongest drivers of momentum.\nAdvocates who had previously been overlooked surfaced naturally through objective criteria.\nSales, Success, and Marketing began operating from shared information rather than assumptions.\nThis shift was less about tools and more about structure. HubSpot simply gave us the environment to create shared clarity.\nOne of the most persistent challenges for advocacy teams is demonstrating the impact of their work. ROI, influenced revenue, readiness forecasting, and coverage gaps are difficult to measure when the underlying data model is fragmented or inconsistently maintained.\nBefore we could optimize workflows or add automation, we needed a data foundation strong enough to support operational and reporting needs at scale.\nTo address this, we designed a Trust Readiness Model that evaluates:\nDesigning this model was the conceptual part. The real work was operationalizing it inside HubSpot in a way that was both reliable and scalable. This required a full data architecture build that included:\nThe impact of this work was immediate. For the first time, we could quantify the influence of advocacy activity across deals, measure real coverage gaps, track readiness trends, and provide clear attribution on revenue. These insights were previously impossible because the system was not architected to support this level of precision.\nOnce the structure was in place, the CRM took over much of the ongoing calculation. We simply had to be deliberate in how we built the foundation.\nOnce the data layer was stable, we shifted our focus to operational design. This was the stage at which the backend architecture evolved into a functional and intuitive process for the teams using it.\nOur goal was to create a system where every action had a clear path, every outcome was measurable, and every stakeholder could see where a request stood without needing to ask.\nWe began by designing a layered dashboard system with distinct views for executives, managers, and operators:\nThen, we created workflow chains that governed intake, routing, notifications, and completion:\nWe also established segmentation rules that filtered advocates based on readiness, permissions, region, product experience, and capacity to ensure accurate and scalable matching.\nAnd we developed branded templates to create consistency in outreach, customer communication, and stakeholder updates, reinforcing professionalism and reducing cognitive load.\nAs the system grew, governance became essential. We implemented:\nThis governance, though not glamorous, prevented drift and helped the system stay reliable even as request volume increased and new team members were onboarded.\nOver time, something meaningful happened. With clearer structure, shared visibility, and a reliable process, advocacy began to be seen not as coordination work but as strategic work that contributed to revenue influence, customer trust, and partnership quality. The system elevated the work simply by revealing its intricacy and value.\nTrust erodes quickly when processes are slow, inconsistent, or unclear — especially in cross-functional work where many people depend on the same information to move a deal forward.\nWe knew that if we wanted advocacy to scale sustainably, the experience needed to feel predictable, fair, and transparent for everyone involved. That meant building a repeatable operating rhythm that mapped cleanly to how real work flows inside HubSpot.\nTo solve this, we created a structured fulfillment sequence that every request moves through:\nRequest → Route → Align → Activate → Frame → Fulfill\nEach stage has a defined purpose, owner, and outcome.\nNothing floats. Nothing gets lost. Nothing relies on memory or individual preference.\nAI played the role of pattern recognition and validation, reducing the manual lift of scanning for product fit, regional alignment, deal size considerations, and past advocacy history. HubSpot helped orchestrate the movement between stages through workflows and tasking, which meant each step was visible, timestamped, and accountable. Humans stepped in where nuance was needed, especially around relationship context, customer readiness, and interpreting the subtleties that no automation can fully understand.\nAs we built this system, something unexpected happened. There was a noticeable increase in empathy toward the work itself. Once teams saw the complexity involved — the judgment calls, the careful framing, the balance between customer care and revenue impact — they developed a deeper appreciation for the people behind the scenes who made the process work. The system made the intricacies visible, and with visibility came more kindness, patience, and collaboration.\nTo reinforce this structure, we introduced a two-person Reference Fulfillment Ops Pod:\nTogether, this created a system where most of the operational load is automated or assisted, but the remaining human decisions are the ones that build trust. That last step is where empathy, discernment, and relationship care come through. And now, with the intricacies made visible, that work is respected and valued in a way it often was not before.\nSystems can enable advocacy, but culture is what sustains it long term. A process will not thrive if people do not see themselves in it or if the work feels transactional. We needed a cultural foundation rooted in mutual recognition, shared ownership, and genuine appreciation for the emotional intelligence required to do this work well.\nAdvocacy is not just operational. It is relational. It requires empathy for both customers and internal teams, and a sensitivity to timing, context, and capacity. The more we surface these intricacies, the more teams understand why thoughtful participation matters.\nTo reinforce this shift, we leaned on learning systems principles and group psychology. Instead of enforcing participation, we modeled the behavior we hoped to inspire. We made the work more transparent, shared context more proactively, and highlighted small wins alongside big ones. We showed how advocacy is connected to customer trust, deal velocity, and long-term relationships.\nOne of the most impactful rituals turned out to be incredibly simple. Each quarter, we recognize the reps who have partnered most actively with the program. We celebrate their collaboration publicly, tag their managers, and acknowledge the ripple effect of their efforts. The recognition was not about scoreboard culture. It was about appreciating the emotional labor, judgment, and relationship-building that often goes unseen.\nThe result was a cultural shift. Advocacy stopped feeling like a request-based motion and began feeling like a shared partnership. With greater visibility came greater empathy. Teams started to understand the intricacies involved and responded with more care, context, and collaboration. Reps participated earlier and more thoughtfully. Managers took pride in their teams’ involvement. Leaders incorporated advocacy insights into planning conversations.\nReciprocity became the cultural norm because the work finally felt understood.\nMany systems track activity, but very few are designed to elevate the humans doing the work. Rebuilding the reference process gave us the chance to build something more thoughtful. A structure that:\nHubSpot provided the tools, the architecture provided clarity, and the people provided heart and meaning.\nIf there is one thing this rebuild taught me, it is that trust is not created by chance. It is created by systems that respect the people doing the work and make it possible for them to operate with clarity, consistency, and care.\nWhat we built at HubSpot is only one example of what this can look like. The details will vary for every team, but the underlying principles remain the same:\nThis case study is especially designed for teams who are building within constraints. For the operators who live inside CRMs and spreadsheets, trying to create order from inherited chaos. For the program managers who may not have a dedicated engineering partner or a budget for a dozen specialized tools, but who do have access to HubSpot and a clear vision of what they want the customer experience to feel like.\nYou don’t need a complex tech stack to build something meaningful. You need clarity, thoughtful architecture, and the willingness to solve for the humans on both sides of the process. The rest can be built, improved, and iterated one layer at a time.\nIf you recognize yourself in this work, know that you are not alone. The impact you create may not always be visible, but it is measurable, repeatable, and essential. And with the right system behind you, it becomes scalable too."
  },
  {
    "url": "https://www.searchenginejournal.com/core-web-vitals-champ-open-source-versus-proprietary-platforms/563796/",
    "title": "Core Web Vitals Champ: Open Source Versus Proprietary Platforms via @sejournal, @martinibuster",
    "date": "2025-12-19T11:29:46+00:00",
    "content": "The Core Web Vitals Technology Report by the open source HTTPArchive community ranks content management systems by how well they perform on Google’s Core Web Vitals (CWV). The November 2025 data shows a significant gap between platforms with the highest ranked CMS scoring 84.87% of sites passing CWV, while the lowest ranked CMS scored 46.28%.\nWhat’s of interest this month is that the top three Core Web Vitals champs are all closed source proprietary platforms while the open source systems were at the bottom of the pack.\nCore Web Vitals (CWV) are metrics created by Google to measure how fast, stable, and responsive a website feels to users. Websites that load quickly and respond smoothly keep visitors engaged and tend to perform better in terms of sales, reads, and add impressions, while sites that fall short frustrate users, increase bounce rates, and perform less well for business goals. CWV scores reflect the quality of the user experience and how a site performs under real-world conditions.\nThe CWV Technology Report combines two public datasets.\nThe Chrome UX Report (CrUX) uses data from Chrome users who opt in to share performance statistics as they browse. This reflects how real users experience websites. The HTTP Archive runs lab-based tests that analyze how sites are built and whether they follow performance best practices.\nTogether, the report I generated provides a snapshot of how each content management system performs on Core Web Vitals.\nDuda ranked first in November 2025, with 84.87% of sites built on the platform delivering a passing Core Web Vitals score. It was the only platform in this comparison where more than four out of five sites achieved a good CWV score. Duda has consistently ranked #1 for Core Web Vitals for several years now.\nWix ranked second, with 74.86% of sites passing CWV. While it trailed Duda by ten percentage points, Wix was just about four percentage points ahead of the third place CMS in this comparison.\nSquarespace ranked third, at 70.39%. Its CWV pass rate placed it closer to Wix than to Drupal, maintaining a clear position in the top three ranked publishing platforms.\nDrupal ranked fourth, with 63.27% of sites passing CWV. That score put Drupal in the middle of the comparison, below the three private label site builders. This is a curious situation because the bottom three CMS’s in this comparison are all open source platforms.\nJoomla ranked fifth, at 56.92%. While more than half of Joomla sites passed CWV, the platform remained well behind the top performers.\nWordPress ranked last, with 46.28% of sites passing Core Web Vitals. Fewer than half of WordPress sites met the CWV thresholds in this snapshot. What’s notable about WordPress’s poor ranking is that it lags behind the fifth place Joomla by about ten percentage points. So not only is WordPress ranked last in this comparison, it’s decisively last.\nCore Web Vitals scores translate into measurable differences in how users experience websites. Platforms at the top of the ranking deliver faster and more stable experiences across a larger share of sites, while platforms at the bottom expose a greater number of users to slower and less responsive pages. The gap between Duda and WordPress in the November 2025 comparison was nearly 40 percentage points, 38.59 percentage points.\nWhile an argument can be made that the WordPress ecosystem of plugins and themes may be to blame for the low CWV scores, the fact remains that WordPress is dead last in this comparison. Perhaps WordPress needs to become more proactive about how themes and plugins perform, such as come up with standards that they have to meet in order to gain a performance certification. That might cause plugin and theme makers to prioritize performance.\nI have mentioned this before and will repeat it this month. There have been discussions and debates about whether the choice of content management system affects search rankings. Some argue that plugins and flexibility make WordPress easier to rank in Google. But the fact is that private platforms like Duda, Wix, and Squarespace have all focused on providing competitive SEO functionalities that automate a wide range of technical SEO tasks.\nSome people insist that Core Web Vitals make a significant contribution to their rankings and I believe them. But in general, the fact is that CWV performance is a minor ranking factor.\nNevertheless, performance still matters for outcomes that are immediate and measurable, such as user experience and conversions, which means that the November 2025 HTTPArchive Technology Report should not be ignored.\nThe HTTPArchive report is available here but it will be going away and replaced very soon. I’ve tried the new report and, unless I missed something, it lacks a way to constrain the report by date."
  }
]