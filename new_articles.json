[
  {
    "url": "https://blog.hubspot.com/marketing/how-simple-semantics-increased-our-ai-citations-by-642-new-results",
    "title": "How simple semantics increased our AI citations by 642% [New results]",
    "date": "2026-01-13T10:00:04+00:00",
    "content": "Like your weird uncle, nobody knows exactly how AI engines choose the sources they cite. But experiments are starting to point to ways you can get on their radar.\nAnd as consumers increasingly turn to AI search for product and service recommendations, you really want to be on their radar. (Ironically, unlike your weird uncle, who you try to avoid.)\nToday, I’ve got one such experiment that contributed to a 642% increase in citations by AI tools like ChatGPT.\nAnd to the delight of you word nerds, it’s all about semantics. But first, everyone’s favorite part: The disclaimer!\nBefore you go any further, it’s important to know that this tactic is just one piece of a wider playbook our Growth team lovingly calls the “everything bagel strategy.”\n“Our experimentation hasn’t [shown that] this one tactic is the key to better AI visibility,” says Amanda Sellers, HubSpot’s head of EN blog strategy. “ What we’ve found is that the sum of the parts is what’s good for AI visibility. ”\nBut if I covered all of those parts at once, this would be a novel, not a newsletter — so think of this more like part 1.\n“A human might be able to tell you what the sentence ‘Paris is cool’ means,” Sellers says. “But an AI engine without [immediate] context wouldn’t know if we’re talking about Paris, France, or Paris Hilton. ”\nAI tools can sound very human, but the way they understand language is very different from us.\nKeeping with Sellers’ example about Paris, before reading, you would know from the start whether an article you clicked on was about travel tips or one about celebrity gossip. That context would be all you needed to understand the word “Paris.” AI models need a little more handholding.\nOne way to coddle their cold, metallic hands is with a framework called “semantic triples.”\nAs simply as I can explain it: Semantic triples are a writing pattern that creates context using the sequence subject – predicate – object.\nIf you also pushed third-grade English out of your brain to make room for Lord of the Rings trivia, here’s a very quick recap of what those mean:\nA real-world marketing example might look like: “HubSpot (subject) can automate (predicate) email marketing (object).”\nWith only one sentence, I’m able to quickly guide a bot to connect HubSpot with email automation. Why does that matter?\n“We want HubSpot to be associated with ‘marketing automation,’ so that when someone asks ChatGPT, ‘What’s the best marketing automation platform?’ we’re mentioned in that conversation.”\nDuring the experiment, Sellers’ team took key information on pages that they wanted AI models to understand, and rewrote it from paragraph format into a bulleted list of semantic triples.\nBelow is a snapshot from Sellers’ recent INBOUND presentation that highlights what that content looked like before and after the changes.\nIn conjunction with the other “everything bagel” ingredients (like schema, backlinks, etc.), this tactic helped to increase mentions of HubSpot in AI answers by 58% , and the number of times HubSpot pages were cited by AI by 642%.\nNow, to some of you, this may just sound like very basic good SEO, and you’re not wrong.\n“It’s very important to have a stable SEO foundation to have good LLM visibility. But while semantic triples are beneficial for SEO, they’re necessary for AEO. ”\nTo others, this may sound like really annoying content for a human to read. And you’re not entirely wrong either. Done poorly, semantic triples can read like the overoptimized garbage that dominated early SEO.\nLuckily, Sellers offered up some practical tips on how to effectively use semantic triples without effectively alienating your audience.\n“We need to find the happy medium between having the content be easily understood [by AI],” and having content that’s still enjoyable for humans to read. With a laugh, Sellers advises using the benchmark, “ Would reading this as a human make me throw my phone in the pool? ”\nInstead of cramming semantic triples all over the page, she suggests tossing in one triple for each core concept along the way.\nYou might think you could get around the need for the first tip by simply writing separate content for AI engines and for your human audience. Sellers advises against this.\nIf AI or search engine crawlers discover your human-focused content, they may decide to penalize both pieces of content for being overly similar.\nBut worse is what happens when your human readers stumble over your bot content. A reputation for crappy content is hard to shake.\n“We’re really trying to do a feed-two-birds-with-one-scone approach, because we have a massive readership that actually cares about what we write.”\nBoth humans and bots like to skim, and your content, however amazing, isn’t the exception. Your job is to make sure they can quickly get key information while skimming.\nTo that end, Sellers recommends using answer-first phrasing.\nSo instead of a sentence like “According to recent research, pizza is delicious,” you might rewrite it as, “Pizza is delicious, according to recent research.”\nA warning: Both human and software editors absolutely hate this. Do it anyway. This is a structure I absolutely insisted on when I was leading the HubSpot Blog’s user acquisition program.\nSimilar to putting key info at the front of a sentence, you also want to make sure your semantic triples appear early within paragraphs.\nAgain, this makes it easy for human skimmers to quickly get the information they’re looking for. But for bots, it’s even more important, because they often take chunks of content out of context.\n“Writers need to be conscientious about the order of sentences, so that if an LLM came and took this one paragraph, it’s enough to represent the idea. ”\nProduct reviews, product comparisons, and listicles are all great places to employ semantic triples. Readers expect this kind of content to be simple and blunt, so semantic triples don’t feel out of place.\nIt’s also a natural opportunity to connect your brand to a product category, to certain features, or even… to your competitors.\n“You want your entity to be associated with similar entities. So, for example, we want HubSpot associated with Salesforce or MailChimp. That way, any time an AI engine mentions a competitor, it would be remiss to not also mention us in the same breath. ”\nIf you’re not sure where you stand in the eyes of the answer engines, it’s super easy to find out using HubSpot’s free AEO grader .\nI sat down to write a How-To for you, and realized it’s so easy it would almost be insulting.\nJust plug in four simple answers, and you’ll get ranked in areas like brand recognition, sentiment, and share of voice for the three most common AI search tools. You then have the option of providing your email address to get a detailed report of insights and recommendations."
  },
  {
    "url": "https://www.searchenginejournal.com/google-downplays-geo-but-lets-talk-about-garbage-ai-serps/564901/",
    "title": "Google Downplays GEO – But Let’s Talk About Garbage AI SERPs via @sejournal, @martinibuster",
    "date": "2026-01-13T10:17:25+00:00",
    "content": "Google’s Danny Sullivan and John Mueller’s Search Off The Record podcast offered guidance to SEOs and publishers who have questions about ranking in LLM-based search and chat, debunking the commonly repeated advice to “chunk your content.” But that’s really not the conversation Googlers should be having right now.\nGoogle used to rank content based on keyword matching and PageRank was a way to extend that paradigm using the anchor text of links. The introduction of the Knowledge Graph in 2012 was described as a step toward ranking answers based on things (entities) in the real world. Google called this a shift from strings to things.\nWhat’s happening today is what Google in 2012 called “the next generation of search, which taps into the collective intelligence of the web and understands the world a bit more like people do.”\nSo, when people say that nothing has changed with SEO, it’s true to the extent that the underlying infrastructure is still Google Search. What has changed is that the answers are in a long-form format that answers three or more additional questions beyond the user’s initial query.\nThe answer to the question of what’s different about SEO for AI is that the paradigm of optimizing for one keyword for one search result is shattered, splintered by the query fan-out.\nGoogle’s Danny Sullivan and John Mueller took a crack at offering guidance on what SEOs should be focusing on. Do they hit the mark?\nGiven that Google is surfacing multi-paragraph long answers, does it make sense to create content that’s organized into bite-sized chunks? How does that affect how humans read content, will they like it or leave it?\nMany SEOs are recommending that publishers break up the page up into “chunks” based on the intuition that AI understands content in chunks, dividing up the page into sections. But that’s an arbitrary approach that ignores the fact that a properly structured web page is already broken into chunks through the use of headings, HTML elements like ordered and unordered lists. A properly marked up and formatted web page should already be formatted into logical structure that a human and a machine can easily understand. Duh… right?\nIt’s not surprising that Google’s Danny Sullivan warns SEOs and publishers to not break their content up into chunks.\n“To go to one of the things, you know, I talked about the specific things people like, “What is the thing I need to improve.” One of the things I keep seeing over and over in some of the advice and guidance and people are trying to figure out what do we do with the LLMs or whatever, is that turn your content into bite-sized chunks, because LLMs like things that are really bite size, right?\nSo we don’t want you to do that. I was talking to some engineers about that. We don’t want you to do that. We really don’t. We don’t want people to have to be crafting anything for Search specifically. That’s never been where we’ve been at and we still continue to be that way. We really don’t want you to think you need to be doing that or produce two versions of your content, one for the LLM and one for the net.”\nDanny talked about chunking with some Google engineers and his takeaway from that conversation is to recommend against chunking. The second takeaway is that their systems are set up to access content the way human readers access it and for that reason he says to craft the content for humans.\nBut again, he avoids talking about what I think is the more important facet of AI search, query fan-out and the impact to referrals. Query fan-out impacts referrals because Google is ranking a handful of pages for multiple queries for every one query that a user makes. But compounds this situation, as you will see further on, is that the sites Google is ranking do not measure up.\nDanny Sullivan next discusses the downside of optimizing for a machine, explaining that systems eventually improve that usually means that optimization for machines stop working.\n“And then the systems improve, probably the way the systems always try to improve, to reward content written for humans. All that stuff that you did to please this LLM system that may or may not have worked, may not carry through for the long term.\n…Again, you have to make your own decisions. But I think that what you tend to see is, over time, these very little specific things are not the things that carry you through, but you know, you make your own decisions. But I think also that many people who have been in the SEO space for a very long time will see this, will recognize that, you know, focusing on these foundational goals, that’s what carries you through.”\nI have known Danny Sullivan for a long time and have a ton of respect for him, I know that he has publishers in mind and that he truly wants for them to succeed. What I wished he would talk about is the declining traffic opportunities for subject-matter experts and the seemingly arbitrary garbage search results that Google consistently surfaces.\nGoogle is intentionally hiding expert publications in the search results, hidden away in the More tab. In order to find expert content, a user has to click the More tab and then click the News tab.\nThis search was not cherry-picked to show poor results. This is literally the one search I did asking a legit question about styling a sweatshirt.\n1. An abandoned Medium Blog from 2018, that only ever had two blog posts, both of which have broken images. That’s not authoritative.\n2. An article published on LinkedIn, a business social networking website. Again, that’s not authoritative nor trustworthy. Who goes to LinkedIn for expert style advice?\n3. An article about sweatshirts published on a sneaker retailer’s website. Not expert, not authoritative. Who goes to a sneaker retailer to read articles about sweatshirts?\nHad Google defaulted to actual expert sites they may have linked to an article from GQ or the New York Times, both reputable websites. Instead, Google hides the high quality web pages under the More tab.\nThis whole thing about GEO or AEO and whether it’s all SEO doesn’t really matter. It’s all a bunch of hand waving and bluster. What matters is that Google is no longer ranking high quality sites and high quality sites are withering from a lack of traffic.\nI see these low quality SERPs all day long and it’s depressing because there is no joy of discovery in Google Search anymore. When was the last time you discovered a really cool site that you wanted to tell someone about?\nEven the YouTube videos, when it comes to subjects where I know something about it, it’s garbage content by garbage creators who are not subject matter experts. There’s a YouTube channel of a couple of guys who do absurd cooking experiments that help no one be a better cook and they’re just rolling in money doing it. I watched a fishing video where the guy is using braid for ultralight fishing and not being able to cast very far because braid is the wrong kind of line for this kind of fishing. I watched another video by some guy who went to the San Francisco Bay, drops a  dinky freshwater lure into the powerful saltwater currents that carry it away. Then he ties a weight to his lure to make it heavier and the entire rig helicopters in the air because it was a dumb thing to do.\nGarbage on garbage, on garbage, on top of more garbage. Google needs a reset.\nHow about Google brings back the original search and we can have all the hand-wavy Gemini stuff under the More tab somewhere?"
  }
]