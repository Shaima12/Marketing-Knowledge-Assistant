[
  {
    "url": "https://www.searchenginejournal.com/ai-overviews-disappears-on-certain-kinds-of-finance-queries/565389/",
    "title": "Data Shows AI Overviews Disappears On Certain Kinds Of Finance Queries via @sejournal, @martinibuster",
    "date": "2026-01-20T11:09:17+00:00",
    "content": "New data from BrightEdge shows how finance-related queries perform on AI Overviews, identifying clear areas that continue to show AIO while Google is pulling back from others. The deciding factor is whether the query benefits from explanation and synthesis versus direct data retrieval or action.\nFinance queries with an educational component, such as “what is” queries trigger a high level of AI Overviews, generating and AIO response as high as 91% of the time.\nExamples of finance educational queries that generate AI Overviews:\nTwo areas where AIO stays out are local type queries or queries where real-time accuracy are of the essence. Local queries were initially a part of the original Search Generative Experience results in 2023, showing AI answers 90% of the time. That dropped to about 10% of the time.\nThe data also shows that “brand + near me” and other “near me” queries are dominated by local pack results and Maps integrations.\nTool and real-time information needs are no longer triggering AI Overviews. Finance calculator queries only shows AI Overviews 9% of the time. Other similar queries show no AI Overviews at all such as:\nThe BrightEdge data shows that these real-time data topics do not generate AIO or generate a low amount:\nExamples of queries Google AI generally keeps out of:\nThe direction Google takes for virtually anything search related depends on user feedback and the ability to show relevant results. It’s not uncommon for some in SEO to underestimate the power of implicit and explicit user feedback as a force that moves Google’s hands on when to show certain kinds of search features. Thus it may be that users are not satisfied with synthesized answers for real-time, calculator and tool, and local near me types of queries.\nAnother area where AI Overviews are rarely if ever shown are finance queries that have a brand name as a component of the query. Brand login queries show AIO only zero to four percent of the time. Brand navigational queries do not show any AI search results.\nThe finance queries where AIO tends to dominate are those with an educational or explanatory intent, where users are seeking to understand concepts, compare options, or receive general guidance rather than retrieve live data, use tools, or complete a navigational task.\nThe data shows AIO dominating these kinds of queries:\nAs previously noted, Google doesn’t arbitrarily decide to show AI answers based on its judgments. User behavior and satisfaction signals play a large role. The fact that AI answers dominates these kinds of answers shows that AIO tends to satisfy users for these kinds of finance queries with a strong learning intent. This means that showing up as a citation for these kinds of queries requires carefully crafting content with a high level of precise answers. In my opinion, I think that a focus on creating content that is unique and doing it on a predictable and regular basis sends a signal of authoritativeness and trustworthiness. Definitely stay away from tactic of the month approaches to content.\nEducational and guidance content have a high visibility in AI responses, not just organic rankings. Visibility increasingly depends on being cited or referenced. It may be useful to focus not just on text content but to offer audio, image, and video content. Not only that, but graphs and tables may be useful ways of communicating data, anything that can be referenced as an answer or to support the answer may be useful.\nTraditional ranking factors still hold for high-volume local, tool, and real-time data queries. Live prices, calculators, and local searches continue to operate under conventional SEO factors.\nFinance search behavior is increasingly segmented by intent and topic. Each query type follows a different path toward AI or organic results. The underlying infrastructure is still the same classic search which means that focusing on the fundamentals of SEO plus expanding beyond simple text content to see what works is a path forward.\nRead BrightEdge’s data on finance queries and AI: Finance and AI Overviews: How Google Applies YMYL Principles to Financial Search\nFeatured Image by Shutterstock/Mix and Match Studio"
  },
  {
    "url": "https://www.blogdigital.fr/a-b-testing-definition-et-meilleures-strategies/",
    "title": "A/B testing : définition et meilleures stratégies pour bien l’exploiter",
    "date": "2026-01-20T11:12:54+00:00",
    "content": "Un moyen de transformer vos intuitions en décisions mesurables ?\nChoisir entre deux titres d’e-mail, hésiter sur la couleur d’un bouton d’ajout au panier ou encore sur la structure d’une page n’a rien d’anecdotique. En effet, tous ces arbitrages façonnent directement la performance de vos actions marketing. Et pour cela, l’A/B testing répond justement à ce besoin , car il vous permet de trancher sur la base de données observables plutôt que de simples ressentis.\nLongtemps réservé aux équipes très outillées dans les grands groupes, l’A/B testing est désormais accessible à un plus large éventail d’entreprises. A l’heure où chaque interaction en ligne compte, cette méthode pourrait bien vous permettre d’identifier ce qui déclenche réellement l’engagement, la conversion ou la prise de contact.\nSi vous ne connaissez pas l’ A/B testing , il est pourtant fort probable que vous y ayez déjà eu l’occasion d’y être confronté, sans même vous en rendre compte.\nConcrètement, l’A/B testing consiste à comparer deux versions d’un même élément auprès d’audiences équivalentes. Ainsi, la version A sert de référence, tandis que la version B comprend une modification ciblée en amont. Après une période définie, les performances sont ensuite mesurées selon un objectif défini, comme les ouvertures, les clics, les soumissions de formulaire ou encore les conversions.\nPour bien fonctionner, le mécanisme repose sur trois piliers, avec la répartition aléatoire du trafic entre les deux variantes, la modification unique pour isoler l’impact réel, et l’ analyse quantitative fondée sur des indicateurs précis.\nLoin de se limiter aux sites web traditionnels, cette approche s’applique à une grande variété de supports, allant des e-mails, des pages de destination, ou des éléments bien plus précis comme des CTA (Call to Action), des formulaires ou même des séquences automatisées. Dans un A/B test, chaque test enrichit la compréhension du comportement de l’utilisateur et vise à alimenter une logique d’optimisation continue.\nSi vous souhaitez expérimenter ces mécanismes dans un cadre réel, il est d’ailleurs possible de créer un compte gratuit HubSpot et d’accéder immédiatement aux fonctionnalités d’A/B testing pour tester vos hypothèses sur vos propres campagnes.\nAlors que d’autres solutions impliquent d’ajouter des extensions complémentaires, HubSpot intègre nativement des outils d’A/B testing dans ses différents hubs, ce qui permet d’expérimenter sans dépendre d’autres outils et sans réaliser de manipulations techniques.\nLes e-mails restent un terrain d’expérimentation privilégié, et avec une solution comme HubSpot, plusieurs variables peuvent être testées comme l’ objet de l’e-mail, le nom de l’expéditeur , la structure du message , la présence ou non d’ images , et même la position et la formulation des CTA .\nUne fois que les éléments sont définis, la plateforme répartit automatiquement l’envoi sur un échantillon représentatif, puis diffuse la version la plus performante au reste de la base. Cette logique s’applique aussi aux séquences d’e-mail commerciaux, ce qui permet d’ajuster progressivement les messages de prospection.\nSelon les chiffres avancés par l’éditeur, les utilisateurs du Sales Hub constatent une amélioration de la productivité en moins d’un mois dans 82% des cas , notamment grâce à ce type d’optimisation ciblée.\nEncore aujourd’hui, les pages web s’avèrent être un levier direct sur la génération de leads. HubSpot propose deux approches complémentaires avec des tests A/B classiques avec une répartition fixe du trafic et des tests adaptatifs jusqu’à cinq variantes, avec une redistribution dynamique via l’intelligence artificielle.\nLà encore, les éléments qui peuvent être testés sont variés et comprennent des titres et des sous-titres, des argumentaires, des visuels, des témoignages de clients, la longueur et la structure des formulaires, et les boutons d’appel à l’action.\nLes clients qui utilisent le Marketing Hub observent en moyenne une augmentation de 167% du trafic web après six mois , ce qui renforce l’intérêt d’optimiser ces pages à fort volume.\nEnfin, au sein des formulaires de conversion, les CTA sont souvent sous-estimés, alors qu’ils conditionnent l’action finale de l’utilisateur. HubSpot permet de comparer différentes variantes selon les éléments que vous souhaitez, comme le texte d’un bouton, la couleur, la position dans la page, ou le design.\nEn règle générale, ces tests sont mis en place à travers des variantes de pages. Le nombre de champs, leur ordre ou l’utilisation de champs progressifs influencent fortement le taux de conversion. Dans certains cas, selon les tests, un formulaire plus court peut d’ailleurs générer davantage de leads, mais parfois moins qualifiés.\nQue ce soit avec HubSpot ou avec une autre solution, vous devrez suivre des étapes bien définies pour vous assurer que votre projet d’A/B testing soit réussi :\nAvant toute chose, vous devez déterminer ce que vous cherchez à améliorer , comme des ouvertures, des clics, les conversions ou la qualification des leads. Dans le cas de HubSpot, cet objectif conditionne directement les indicateurs analysés dans la solution.\nUn A/B test réussi repose sur une règle simple où vous devez réaliser une seule modification à la fois , car tester simultanément plusieurs changements rend l’interprétation impossible. Si vous suivez bien cette discipline, vous pourrez être assuré de pouvoir en tirer des enseignements exploitables.\nDepuis l’éditeur d’e-mails, de pages ou de CTA, HubSpot permet de dupliquer un contenu et d’en créer une version alternative en seulement quelques clics. La plateforme gère ensuite la distribution du trafic et le suivi des performances, sans que vous n’ayez besoin d’y passer plus de temps.\nPour les e-mails, si vous le souhaitez, il est aussi possible de définir la taille de l’échantillon du test et la durée , avant la sélection automatique du test gagnant.\nUn test fiable nécessite du volume et du temps . En pratique, une durée d’une à deux semaines au minimum est souvent nécessaire.\nVous pouvez décider d’interrompre un A/V test plus tôt, mais cela vous expose à des biais liés aux variations ponctuelles du trafic à terme.\nEnfin, si vous utilisez HubSpot, vous avez l’avantage d’avoir accès à des tableaux de bord qui centralisent les données. Vous y retrouverez le taux d’ouverture, les clics, les conversions, mais aussi surtout l’impact réel sur l’ensemble du funnel.\nCette vision d’ensemble est l’un des atouts majeurs de la plateforme, car elle permet d’unifier les données marketing, commerciales et relationnelles, si bien que 83% des clients HubSpot estiment que cela facilite une lecture cohérente de la performance.\nSi, dans l’ensemble, c’est d’abord l’accumulation de tests A/B qui vous permettra de progresser, il vous faudra aussi suivre ces bonnes pratiques au départ :\nL’A/B testing s’inscrit dans une logique d’amélioration continue . Les équipes qui testent le plus souvent accumulent des enseignements actionnables plus rapidement, souvent modestes pris isolément, mais très efficaces dans la durée.\nIl est beaucoup plus judicieux de tester une landing page très visitée, plutôt qu’un contenu secondaire de votre site web. A terme, quand elle est bien réalisée, cette priorisation vous permet d’obtenir des résultats plus rapides et plus fiables.\nSi les solutions comme HubSpot fournissent des indicateurs de fiabilité, il reste indispensable d’avoir un volume suffisant . Par exemple, pour les e-mails, vous devez avoir au moins 100 contacts par variante au minimum, et pour les pages web, le besoin varie selon le taux de conversion initial.\nUn résultat présenté de façon trop « global » peut masquer des différences par segment, comme les nouveaux visiteurs, les leads chauds, ou les clients existants. HubSpot a la capacité de pouvoir croiser les résultats avec les propriétés CRM pour affiner l’interprétation, et éviter les conclusions contradictoires.\nN’oubliez pas de toujours conserver une trace de vos A/B tests déjà réalisés . En plus d’éviter de reproduire les mêmes expérimentations au fil du temps, cela vous permettra aussi d’accélérer la montée en compétence collective.\nEnfin, parmi les bonnes pratiques, il y a aussi quelques erreurs fréquentes que l’on retrouve dans les entreprises et que vous vous devez d’éviter.\nAvant que cela ne devienne un réflexe, assurez-vous de ne jamais modifier plusieurs variables simultanément , et de ne pas arrêter un test dès les premiers signaux . Même un test qui ne montre aucune différence apporte une information utile, car il permet d’écarter une piste et de concentrer les efforts ailleurs. Cela signifie qu’ il ne faut pas ignorer un résultat non-concluant , ni se focaliser uniquement sur le taux de clic sans analyser la qualité des leads.\nEn général, une à deux semaines minimum sont nécessaires pour un test A/B, mais pour des cycles d’achat plus longs ou des volumes faibles, le test peut durer plus longtemps.\nOui, les tests adaptatifs sur les pages web autorisent jusqu’à cinq variantes simultanées.\nLa plateforme se base sur l’indicateur défini au départ, comme l’ouverture, le clic ou la conversion, et sélectionne automatiquement la version la plus performante."
  }
]